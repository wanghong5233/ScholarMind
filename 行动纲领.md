# ScholarMind 项目行动纲领 (V1.0)

**项目核心定位：** 不仅仅是一个“文档问答”工具，而是旨在成为一个**能够深度理解多模态学术论文**、**支持多文档上下文**、并**辅助研究人员进行文献综述、思路启发和论文草稿撰写**的**高级科研助理**。

---

## 第零阶段：项目净化与品牌重塑 (Phase 0: Purification & Rebranding)

**目标：** 彻底抹去旧项目的痕跡，注入 `ScholarMind` 的灵魂，让整个项目从内到外都成为您自己的作品。这是专业开发的第一步。

**核心价值：** 向面试官展示您专业的工程素养、对项目所有权的严肃态度和优秀的文档能力。

### 关键任务 (Tasks)

1.  **全面重命名 (Branding):**
    *   **描述**: 审视整个代码库，将所有与旧项目相关的命名（例如 `docker-compose.yml` 中的服务名 `swxy_api`、配置文件中的变量、代码注释、日志输出等）全部替换为 `scholarmind` 或其他相关的中性名称。
    *   **细化要点**:
        *   统一 `docker-compose.yml` 服务与网络命名：`scholarmind_api`、`scholarmind_db`、`scholarmind_vector`。
        *   统一 `.env` 键名前缀：例如 `SM_`（如 `SM_RAG_TOPK`, `SM_EMBEDDER_TYPE`）。
        *   替换代码中残留的产品文案、接口前缀、日志Tag，确保品牌一致性。
    *   **产出物**: 一个干净的、完全属于 `ScholarMind` 品牌的代码库。

2.  **代码清理 (Code Cleanup):**
    *   **描述**:
        *   删除旧项目中任何与金融研报场景强相关的、在新场景下无用的代码（如特定的解析规则、API端点）。
        *   清理掉所有废弃的、被注释掉的代码块，保持代码的整洁。
    *   **产出物**: 一个更轻量、更专注、可读性更高的代码库。

3.  **项目文档初始化 (Documentation):**
    *   **描述**: 精心编写第一版 `README.md`，内容应包括：
        *   项目Logo与徽章 (Badges)。
        *   清晰的项目定位和一句话介绍。
        *   核心功能列表 (Features)。
        *   包含 `docker-compose up -d` 的快速启动指南。
        *   明确的技术选型 (Tech Stack)。
        *   一个高级别的开发路线图 (Roadmap)，链接到本计划。
    *   **产出物**: 一个专业、信息全面的 `README.md` 文件。

4.  **环境与开源合规初始化 (Env & OSS readiness):**
    *   **描述**:
        *   添加 `.env.example`，覆盖 Embedding/Reranker/LLM 的可切换配置占位（见Phase 1“配置中心化”）。
        *   明确许可证 `LICENSE`（推荐 MIT）并在 `README.md` 标注。
        *   初始化 `CONTRIBUTING.md`、`CODE_OF_CONDUCT.md`（可简化模板）。
    *   **产出物**: `.env.example`、`LICENSE`、`CONTRIBUTING.md` 草案。

---

## 第一阶段：架构重构与基础加固 (Phase 1: Architectural Refactoring)

**目标：** 解决原项目的核心架构缺陷（硬编码、高耦合），搭建一个“高内聚、低耦合”、可扩展、可维护的“可插拔”系统。

**核心价值：** 这是整个项目中**技术含金量最高**的部分之一。它能集中体现您的软件设计能力、架构思维和对生产环境的理解（成本、安全、性能）。

### 关键任务 (Tasks)

1.  **实现依赖注入 (Dependency Injection):**
    *   **具体问题定位**:
        *   **Reranker强耦合**: `rerank_by_model` 方法未实际使用传入的 `rerank_mdl` 参数，而是在其内部硬编码创建了一个 `DashScopeRerank` 实例。
        *   **Embedding链路混乱**: `Dealer.get_vector` 方法定义了 `emb_mdl` 参数却并未使用，而是转头调用了依赖全局环境变量的 `generate_embedding` 函数，导致上层参数被架空。
    *   **描述**:
        1.  创建 `backend/app/service/core/components` 目录。
        2.  在其中定义 `BaseEmbedder`, `BaseReranker`, `BaseLLM` 等抽象基类（接口），明确统一的调用方法（如 `embed_documents`, `rerank`, `generate`）。
        3.  重构 `Dealer` 等核心服务类，使其构造函数 `__init__` 接收这些接口的实例，而不是在内部创建；`Dealer.get_vector` 改为直接使用 `self.embedder`。
        4.  重构 `rerank_by_model`，接收实现 `BaseReranker` 的实例并调用其 `rerank`（移除内部创建具体Reranker的逻辑）。
        5.  彻底移除或废弃 `model.py` 中 `generate_embedding` 等与全局状态耦合的函数。
    *   **产出物**: 一套清晰的组件接口定义；一个遵循依赖注入原则的、解耦的RAG核心层；`Dealer`/`retrieval` 的新签名与用法文档。

2.  **模型私有化部署 (Model Privatization):**
    *   **核心动机**: 解决原方案依赖商业API带来的**高成本、低效率（网络延迟&吞吐量限制）、数据隐私风险、服务不可控**四大问题。
    *   **描述**:
        1.  将对云端API（如DashScope）的依赖，切换为在本地部署高性能的开源模型；提供“本地/云端”的可配置开关。
        2.  **Embedding模型**: 推荐 `bge-large-zh-v1.5`、`m3e-large`、`gte-large-zh`（择一起步）。
        3.  **Reranker模型**: 推荐 `bge-reranker-large`；封装 `DashScopeReranker` 与本地 `LocalBGEReranker` 两种实现。
        4.  将这些本地模型的加载和调用逻辑，封装成遵循第一步接口的**具体实现类**（如 `LocalBgeEmbedder(BaseEmbedder)`），并提供最小可复现实例（MRE）。
        5.  预留向量数据库兼容层（Elasticsearch/Weaviate/Qdrant/Milvus），仅抽象接口，避免早期过度耦合。
    *   **产出物**: 具体的模型组件实现类；`requirements.txt` 增补（`sentence-transformers`, `torch`）；一份 `benchmark.md`，比较“云端 vs 本地”在吞吐/延迟/成本上的差异。

3.  **配置中心化 (Centralized Configuration):**
    *   **具体问题定位**: `retrieval.py` 的 `retrieve_content` 函数中，直接硬编码了 `page = 1` 和 `page_size = 5`，导致该服务可复用性极差，且无法灵活调整Top-K等重要超参数。
    *   **描述**:
        1.  创建统一配置文件 `backend/app/core/config.py`，使用 `Pydantic BaseSettings` 从 `.env` 读取：
            *   `SM_EMBEDDER_TYPE`、`SM_RERANKER_TYPE`（如 `local`/`dashscope`）。
            *   本地模型路径、批大小、设备（cpu/cuda）。
            *   `SM_RAG_TOPK`、`SM_RETRIEVE_PAGE`、`SM_RETRIEVE_PAGE_SIZE` 等超参数。
        2.  将 `retrieve_content` 中的 `page`/`page_size` 改为函数参数并提供默认值；上移“Top-K”决策到调用方或配置层。
        3.  创建“组件工厂”，按配置实例化 `BaseEmbedder`/`BaseReranker`/`BaseLLM`；支持未来热插拔扩展。
    *   **产出物**: `config.py` 与 `.env.example`；`components_factory.py`；`retrieve_content` 新签名及调用示例。

---

## 第二阶段：核心功能开发——注入“学者”灵魂 (Phase 2: Scholar-Oriented Features)

**目标：** 在坚实的架构之上，开发真正服务于“论文写作”场景的专属功能，让项目从一个通用RAG框架进化为专业的科研助理。

**核心价值：** 展示您将技术与特定业务场景结合的落地能力，以及对前沿技术（多模态、高级检索）的跟进和实践能力。

### 关键任务 (Tasks)

1.  **多模态解析能力 (Multi-modal Ingestion):**
    *   **现状分析**: 原项目的 `PdfParser` 具备提取图片的能力，但这些宝贵的多模态信息在上层被直接丢弃了。
    *   **描述**:
        1.  增强文档解析流程，在识别文本的同时，使用 `PyMuPDF` 或类似工具提取PDF中的**图片**。
        2.  调用一个开源多模态大模型（如本地部署的 `LLaVA` 或 `Qwen-VL` 的API）对图片生成**详细的文字描述**（Image Captioning）。
        3.  将图片本身（存储到对象存储或本地文件系统）的路径、及其生成的文字描述**一起**存入Elasticsearch索引；可选加入图像向量（CLIP等）以支持图文联合检索。
        4.  在生成环节支持将最相关图片随答案一起展示，并附上基于描述的解读。
    *   **产出物**: 增强的文档解析服务；索引中包含图片描述与可选图像向量字段；前端展示示例。

2.  **高级检索策略 (Advanced Retrieval):**
    *   **描述**: 实现至少一种高级检索策略来提升召回精度。
        *   **首选**: **多路召回 (Multi-Query Retrieval)**。用LLM将用户的原始问题分解为3-5个不同角度的子问题，并行检索，最后用**RRF (Reciprocal Rank Fusion) 算法**高效地合并结果。
        *   **备选**: **假设性文档嵌入 (HyDE)**。先让LLM为问题“幻想”一个答案，再用这个幻想答案的向量去检索。
        *   **进阶**: **RAG-Fusion**（结合多路召回与倒数排名融合）。
    *   **产出物**: 可配置的查询扩展模块与RRF实现；A/B评估记录。

3.  **语义分块 (Semantic Chunking):**
    *   **核心动机**: 解决按固定Token数切块，经常**将一句完整的语义从中间切断**，从而破坏上下文完整性的问题。
    *   **描述**: 放弃按固定Token数切块的简单策略。引入 `SentenceTransformers` 库，通过计算句子间向量的语义相似度来决定切分点，确保每个文本块都是一个语义完整的“意群”。
    *   **产出物**: 一个基于语义的 `SemanticChunker` 工具类。

4.  **【新增】改造会话管理，支持多文档问答**:
    *   **核心动机**: 解决原项目 `quick_parse` 只能“一问一答一文档”的局限性，使其不符合用户直觉，且无法满足多文档对比等核心需求。
    *   **描述**: 重构 `chat` 相关的服务和API，使单个聊天会话（Session）可以关联一个或多个知识库文档，允许用户在一个对话中持续就多篇论文进行提问和比较。
    *   **产出物**: 支持多文档上下文的聊天API和后端服务逻辑。

5.  **答案自校准与精确引用 (Self-correction & Citation)**:
    *   **描述**:
        1.  在生成答案后追加“验证回合”，让LLM对照检索上下文检查幻觉并修正。
        2.  将引用粒度细化到“文档-页码-段落/坐标”，返回结构化 citation；前端点击可高亮原文片段。
    *   **产出物**: `post_generation_validator` 模块；引用结构设计与前端高亮示例。

---

## 第三阶段：构筑技术护城河 (Phase 3: Building the Moat)

**目标：** 实现具有高技术壁垒的功能，充分展示您的技术深度和潜力，让您的项目在众多求职者中脱颖而出。

**核心价值：** 这是您冲击高级岗位或顶级公司的“大杀器”。它证明您不仅是“功能实现者”，更是具备“系统优化”和“AI应用创新”-能力的稀缺人才。

### 关键任务 (Tasks)

1.  **构建量化评估体系 (RAG Evaluation):**
    *   **描述**:
        1.  在 `scripts/` 目录下创建一个评估脚本。
        2.  集成 `RAGAs` 或 `TruLens` 评估框架。
        3.  手动构建一个小的评测数据集（20-30个关于几篇核心论文的“问题-标准答案-上下文”对）。
        4.  实现自动化运行评估，并量化计算系统的**忠实度 (Faithfulness)**、**答案相关性 (Answer Relevancy)**、**上下文精确率/召回率 (Context Precision/Recall)**。
    *   **产出物**: 一个 `evaluation.py` 脚本；一份 `evaluation_report.md`，用图表展示每次优化带来的指标提升。

2.  **Agent化：自动化文献综述 (Agentic Workflow):**
    *   **描述**:
        1.  引入**工具调用 (Tool Calling)** 思想，让LLM能自主规划并调用您提供的工具。
        2.  定义一套工具集，如 `search_papers(query: str, year_range: tuple)`、`summarize_content(content: str)`、`generate_references(papers: list)`。
        3.  实现一个API端点，接收用户的复杂指令（如“帮我写一段关于RAG查询扩展技术的综述”），由Agent自主执行，并返回最终结果。
    *   **产出物**: 一个具备初步Agent能力的文献综述服务。

3.  **模型微调 (Fine-tuning) - (可选，但极具价值):**
    *   **描述**:
        1.  **数据集构建**: 利用开源学术数据集（如ArXiv），构建用于排序学习的**三元组（Query, Positive_Passage, Negative_Passage）**。
        2.  **模型微调**: 基于私有化部署的 `bge-reranker-large` 模型，使用构建好的数据集进行微调，让模型更懂您的专业领域。
    *   **产出物**: 微调后的模型权重（可发布到Hugging Face）；一份详细的技术报告，阐述微调方法、过程和效果对比。

4.  **全链路可观测性 (Observability) - (推荐)**:
    *   **描述**:
        1.  记录一次问答全链路：原始问题 -> 查询增强 -> 检索结果 -> 重排结果 -> 最终Prompt -> 模型输出。
        2.  集成 `LangSmith`/`OpenTelemetry` 或自建轻量日志系统；设计统一的Trace ID贯穿后端服务。
        3.  提供调试视图或导出JSON，辅助问题定位与复现实验。
    *   **产出物**: 可观测性中间件；`tracing.md` 使用说明与样例追踪记录。
