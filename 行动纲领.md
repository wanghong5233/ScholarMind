# ScholarMind 项目行动纲领

**项目核心定位：** 不仅仅是一个“文档问答”工具，而是旨在成为一个**能够深度理解多模态学术论文**、**支持多文档上下文**、并**辅助研究人员进行文献综述、思路启发和论文草稿撰写**的**高级科研助理**。

---

## 第零阶段：项目净化与品牌重塑 (Phase 0: Purification & Rebranding)

**目标：** 彻底抹去旧项目的痕跡，注入 `ScholarMind` 的灵魂，让整个项目从内到外都成为您自己的作品。这是专业开发的第一步。

**核心价值：** 向面试官展示您专业的工程素养、对项目所有权的严肃态度和优秀的文档能力。

### 关键任务 (Tasks)

1.  **全面重命名 (Branding):**
    *   **描述**: 审视整个代码库，将所有与旧项目相关的命名（例如 `docker-compose.yml` 中的服务名 `swxy_api`、配置文件中的变量、代码注释、日志输出等）全部替换为 `scholarmind` 或其他相关的中性名称。
    *   **细化要点**:
        *   统一 `docker-compose.yml` 服务与网络命名：`scholarmind_api`、`scholarmind_db`、`scholarmind_vector`。
        *   统一 `.env` 键名前缀：例如 `SM_`（如 `SM_RAG_TOPK`, `SM_EMBEDDER_TYPE`）。
        *   替换代码中残留的产品文案、接口前缀、日志Tag，确保品牌一致性。
    *   **产出物**: 一个干净的、完全属于 `ScholarMind` 品牌的代码库。

2.  **代码清理 (Code Cleanup):**
    *   **描述**:
        *   删除旧项目中任何与金融研报场景强相关的、在新场景下无用的代码（如特定的解析规则、API端点）。
        *   清理掉所有废弃的、被注释掉的代码块，保持代码的整洁。
    *   **产出物**: 一个更轻量、更专注、可读性更高的代码库。

3.  **项目文档初始化 (Documentation):**
    *   **描述**: 精心编写第一版 `README.md`，内容应包括：
        *   项目Logo与徽章 (Badges)。
        *   清晰的项目定位和一句话介绍。
        *   核心功能列表 (Features)。
        *   包含 `docker-compose up -d` 的快速启动指南。
        *   明确的技术选型 (Tech Stack)。
        *   一个高级别的开发路线图 (Roadmap)，链接到本计划。
    *   **产出物**: 一个专业、信息全面的 `README.md` 文件。

4.  **环境与开源合规初始化 (Env & OSS readiness):**
    *   **描述**:
        *   添加 `.env.example`，覆盖 Embedding/Reranker/LLM 的可切换配置占位（见Phase 1“配置中心化”）。
        *   明确许可证 `LICENSE`（推荐 MIT）并在 `README.md` 标注。
        *   初始化 `CONTRIBUTING.md`、`CODE_OF_CONDUCT.md`（可简化模板）。
    *   **产出物**: `.env.example`、`LICENSE`、`CONTRIBUTING.md` 草案。

---

## 第一阶段：架构重构与基础加固 (Phase 1: Architectural Refactoring)

**目标：** 解决原项目的核心架构缺陷（硬编码、高耦合），搭建一个“高内聚、低耦合”、可扩展、可维护的“可插拔”系统。

**核心价值：** 这是整个项目中技术含金量最高的部分之一。它能集中体现您的软件设计能力、架构思维和对生产环境的理解（成本、安全、性能）。

### 关键任务：分步实施计划

我们将 Phase 1 分为四个逻辑部分，共八个可执行的子任务，确保每一步都建立在坚实的基础之上。

---

#### 第一部分：环境与规范 (Environment & Standards)

*本部分旨在为项目搭建生产级的“基础设施”，确保后续开发过程中的稳定性和可维护性。*

**任务1: 实施结构化日志 (Structured Logging)**
*   **目标**: 放弃传统 `print` 或简单 `logging`，引入 `loguru` 库，建立全局统一、可追踪、可分析的日志系统。
*   **关键步骤**:
    1.  配置 `loguru` 将日志输出为 JSON 格式。
    2.  创建 FastAPI 中间件，为每个请求生成唯一的 `request_id`，并将其注入所有后续日志中。
*   **产出物**: `utils/get_logger.py` 模块；FastAPI 日志中间件；结构化的日志输出。

**任务2: 建立标准化异常处理 (Standardized Exception Handling)**
*   **目标**: 构建健壮的全局异常处理机制，向前端返回统一、清晰的错误信息，同时记录详细的错误日志。
*   **关键步骤**:
    1.  创建 `exceptions` 目录，定义业务相关的自定义异常类（如 `ModelNotFoundError`, `VectorStoreError`）。
    2.  在 `app_main.py` 中，使用 FastAPI 的 `exception_handlers` 机制，注册全局异常处理器。
*   **产出物**: 自定义异常类；全局异常处理中间件；标准化的 JSON 错误响应格式。

---

#### 第二部分：核心抽象层 (Core Abstraction Layer)

*本部分是整个“可插拔”架构的核心，我们将用代码定义系统的标准“接口”和“数据语言”。*

**任务3: 定义核心数据模型与组件接口 (Define Core Data Models & Component Interfaces)**
*   **目标**: 彻底解耦数据流和功能模块，为后续所有功能（多模态、高级检索等）奠定基础。
*   **关键步骤**:
    1.  **数据模型**: 在 `schemas` 包下创建 `rag.py`，使用 `Pydantic` 定义 `Document` 和 `Chunk` 等核心数据结构。
    2.  **组件接口**: 创建 `service/core/abstractions` 目录，用于存放所有核心抽象基类（接口）。在其中为 `embedder.py`, `reranker.py`, `llm.py`, `vector_store.py` 分别定义 `BaseEmbedder`, `BaseReranker`, `BaseLLM`, `BaseVectorStore` 接口。
    3.  **接口设计**: 为接口设计统一、面向未来的方法签名，例如为 `BaseLLM` 预留 `stream_generate` 和 `generate_with_tools` 方法。
*   **产出物**: `schemas/rag.py`；`service/core/abstractions` 目录及其内部的接口定义文件。

---

#### 第三部分：配置与实现 (Configuration & Implementation)

*本部分旨在将第二部分的抽象接口“实例化”，并提供一个灵活的“开关”来动态选择使用哪个实例。*

**任务4: 配置中心化与组件工厂 (Centralize Configuration & Build Component Factory)**
*   **目标**: 将所有可变配置（模型类型、路径、API密钥、超参数）从代码中剥离，并创建一个工厂来根据配置动态生成组件实例。
*   **关键步骤**:
    1.  创建 `core/config.py`，使用 `Pydantic BaseSettings` 从 `.env` 文件加载配置。
    2.  创建 `core/components_factory.py`，它能根据 `config.py` 中的设置（如 `SM_EMBEDDER_TYPE`），返回一个具体的 `BaseEmbedder` 实现类的实例。
*   **产出物**: `config.py` 配置文件；`components_factory.py` 组件工厂；更新后的 `.env.example`。

**任务5: 实现模型与向量存储组件 (Implement Model & Vector Store Components)**
*   **目标**: 在规范的目录结构中，为核心抽象接口提供具体的实现类，包括调用本地私有化模型和云端API。
*   **关键步骤**:
    1.  创建 `service/core/implementations` 目录，用于存放所有具体的实现类。
    2.  在该目录下，按组件类型创建子目录，如 `embedders`, `rerankers`, `llms`, `vector_stores`。
    3.  在各自的子目录中，创建具体的实现类文件，例如 `implementations/embedders/local_bge.py` 和 `implementations/embedders/dashscope.py`，这些类都继承自 `abstractions` 中对应的基类。
*   **产出物**: 一个组织清晰的 `service/core/implementations` 目录结构；多个具体的组件实现类（如 `LocalBgeEmbedder`, `DashScopeEmbedder`, `FaissVectorStore` 等）；`requirements.txt` 增补。

---

#### 第四部分：服务集成与重构 (Service Integration & Refactoring)

*本部分是重构的收尾阶段，我们将用新的架构组装业务逻辑，并彻底清理旧代码。*

**任务6: 封装统一服务层 (Encapsulate with a Unified Service Layer)**
*   **目标**: 避免在API层处理复杂的业务逻辑，创建一个高内聚的 `RAGService` 来封装和编排所有底层组件的调用流程。
*   **关键步骤**:
    1.  创建 `service/rag_service.py`。
    2.  `RAGService` 的构造函数接收由组件工厂创建的 `Embedder`, `Reranker`, `LLM`, `VectorStore` 等实例。
    3.  在 `RAGService` 内部实现完整的 RAG 问答流程方法（如 `ask`）。
    4.  **【新增】** 在服务层统一构造符合业务需求的 Prompt 模板（例如，包含引用标注规则），并传递给 `BaseLLM` 实例，以确保 Prompt 的一致性和可维护性。
    5.  **【新增】** 在服务层根据业务逻辑（如会话ID、知识库ID）决定要操作的 Elasticsearch 索引名称，并将其作为参数传递给 `BaseVectorStore` 的方法调用（需要先为接口增加 `index_name` 参数）。
*   **产出物**: `RAGService` 类。

**任务7: 重构API层 (Refactor API Layer)**
*   **目标**: 使 `router` 层变得轻薄、职责单一，只负责HTTP请求的解析和响应的格式化。
*   **关键步骤**:
    1.  创建 `dependencies.py`，提供 `get_rag_service` 等依赖项提供函数。
    2.  重构 `router/chat_rt.py` 等API路由，使其通过 `FastAPI.Depends(get_rag_service)` 获取 `RAGService` 实例，并调用其方法来处理业务。
*   **产出物**: 重构后的 `router` 文件；`dependencies.py` 依赖注入模块。

**任务8: 清理遗留代码 (Cleanup Legacy Code)**
*   **目标**: 完成重构的最后一步，移除所有被新架构替代的旧代码，消除技术债务。
*   **关键步骤**:
    1.  审查 `Dealer`, `chat.py`, `retrieval.py` 等旧模块，删除其中与新架构重复或冲突的逻辑。
    2.  彻底移除 `model.py` 中 `generate_embedding` 等与全局状态耦合的旧函数。
*   **产出物**: 一个代码更整洁、结构更清晰的项目。

---

## 第二阶段：核心功能实现——打造科研助理的核心能力 (Phase 2: Core Feature Implementation)

**目标：** 在坚实的架构之上，开发真正服务于“学者”场景的核心功能，让项目从一个通用RAG框架进化为专业的科研助理。

**核心价值：** 展示您将技术与特定业务场景结合的落地能力，以及对前沿技术（多模态、高级检索）的跟进和实践能力。

### 功能模块一：智能知识库构建 (Intelligent Knowledge Base Construction)

**功能描述：** 这是整个科研工作流的起点。用户可以围绕一个研究主题（如“GNN+DRL+Edge Inference”），通过与 `ScholarMind` 的交互，从海量文献中筛选、构建出一个高度相关的、私有化的本地知识库。

*   **技术实现路径:**
    1.  **在线文献获取与导入 (Online Paper Fetching & Importing):**
        *   **描述**: 实现一个工具，可以连接到 `ArXiv` 等学术搜索引擎的API。用户输入关键词后，系统能自动检索近五年相关的论文列表（标题、摘要、作者）。用户可以通过一个交互界面勾选、确认，系统再自动下载这些论文的PDF，完成知识库的冷启动。
        *   **产出物**: `arxiv_importer.py` 工具模块；一个简单的前端交互界面或后端API。
    2.  **多模态内容解析 (Multi-modal Ingestion):**
        *   **现状分析**: 原项目的 `PdfParser` 具备提取图片的能力，但这些宝贵的多模态信息在上层被直接丢弃了。
        *   **描述**: 增强文档解析流程，在识别文本的同时，使用 `PyMuPDF` 等工具提取PDF中的**图片、表格、公式**。调用一个本地部署的多模态模型（如 `LLaVA` 或 `Qwen-VL`）对图表生成详细的文字描述（Image Captioning）。将这些结构化信息（图片路径、图表描述、公式LaTex）与文本块一同存入Elasticsearch。
        *   **产出物**: 增强的文档解析服务；包含图文描述的、更丰富的索引结构。
    3.  **语义感知分块 (Semantic-Aware Chunking):**
        *   **核心动机**: 解决按固定Token数切块，经常**将一句完整的语义从中间切断**，从而破坏上下文完整性的问题。
        *   **描述**: 放弃按固定Token数切块的简单策略。引入 `SentenceTransformers` 库，通过计算句子间向量的语义相似度来决定切分点，确保每个文本块都是一个语义完整的“意群”。
        *   **产出物**: 一个基于语义的 `SemanticChunker` 工具类。

### 功能模块二：多文档、高精度 RAG 问答 (High-Fidelity, Multi-Document RAG Q&A)

**功能描述：** 这是 `ScholarMind` 的核心交互功能。用户可以在构建好的知识库范围内，用自然语言进行提问。系统不仅能给出精准的答案，还必须提供清晰、可验证的答案来源，并支持在一个对话中围绕多篇论文进行持续的、有上下文的讨论。

*   **技术实现路径:**
    1.  **基础能力：多文档会话 (Multi-Document Session Support):**
        *   **核心动机**: 解决原项目 `quick_parse` 只能“一问一答一文档”的局限性，使其不符合用户直觉，且无法满足多文档对比等核心需求。
        *   **描述**: 重构 `chat` 相关的服务和API，使单个聊天会话（Session）可以关联一个或多个知识库文档，允许用户在一个对话中持续就多篇论文进行提问和比较。
        *   **产出物**: 支持多文档上下文的聊天API和后端服务逻辑。
    2.  **<font color='red'>高级检索策略 (Advanced Retrieval Strategies)</font>:**
        *   **描述**: 实现至少一种高级检索策略来提升召回精度，确保找到最相关的上下文。
            *   **首选**: **多路召回 (Multi-Query Retrieval)**。用LLM将用户的原始问题分解为3-5个不同角度的子问题，并行检索，最后用**RRF (Reciprocal Rank Fusion) 算法**高效地合并结果。
            *   **备选**: **假设性文档嵌入 (HyDE)**。先让LLM为问题“幻想”一个答案，再用这个幻想答案的向量去检索。
        *   **产出物**: 可配置的查询扩展模块与RRF实现；A/B评估记录。
    3.  **答案溯源与高亮 (Citation & Highlighting):**
        *   **描述**: 在生成答案后，必须精确地展示每个论点来源于哪篇论文的哪个部分。将引用粒度细化到“文档ID-页码-段落/坐标”，返回结构化的 `citation` 数据。前端可以根据这些数据，在答案旁边展示引用的原文片段，并提供一个链接，点击后可以直接打开对应的PDF文件并高亮显示相关区域。
        *   **产出物**: `post_generation_validator` 模块；标准化的引用数据结构；前端高亮示例。
    4.  **【亮点功能】<font color='red'>跨论文深度对比分析 (Cross-Paper Comparative Analysis)</font>:**
        *   **功能描述**: 支持用户指定2-3篇论文，提出结构化的对比问题，如“**用表格对比论文A和B在方法论、数据集和性能指标上的异同**”。
        *   **技术价值**: 这要求系统具备更强的结构化信息提取和逻辑推理能力，是高阶的RAG应用。
    5.  **【亮点功能】<font color='red'>批判性问题生成 (Critical Question Generator)</font>:**
        *   **功能描述**: 在用户读完一篇论文后，`ScholarMind` 能主动提出批判性问题，如“**分析论文A的作者在实验部分规避了哪些潜在的负面结果？**”，引导用户深度思考。
        *   **技术价值**: 要求LLM具备反思（Reflection）和批判性思维能力，让项目从“工具”变为“伙伴”。
    6.  **<font color='red'>【核心技术：RL微调】自适应重排序模型 (Adaptive Reranker via RL)</font>:**
        *   **动机**: 传统的Reranker微调依赖静态数据集，无法适应用户的动态偏好。通过强化学习，我们可以利用用户的**隐式反馈**（如点击、滚动）作为奖励信号，让 Reranker 动态地、持续地优化其排序策略，变得越来越懂用户。
        *   **RL建模**:
            *   **状态 (State)**: 用户查询 `Query` 和初步召回的 `Documents` 列表。
            *   **动作 (Action)**: Reranker 对 `Documents` 列表进行**重新排序**。
            *   **奖励 (Reward)**: 当用户在最终答案的引用中**点击**了某个来源，或对某个来源点了“赞”，就给予该排序动作**正奖励**；反之则给予**负奖励**。
        *   **产出物**: 一个通过在线学习持续进化的 Reranker 模型；一套用户反馈收集与奖励计算机制；一份展示模型自适应优化过程的技术报告，这是体现 **RL+RAG** 结合深度的绝佳案例。

---

## 第三阶段：迈向智能助理——实现自动化与深度优化 (Phase 3: Towards an Intelligent Agent & Deep Optimization)

**目标：** 让 `ScholarMind` 从一个“被动问答”的工具，升级为一个能“**主动执行复杂任务**”的智能助理，构筑项目的核心技术壁垒。

**核心价值：** 这是您冲击高级岗位或顶级公司的“大杀器”。它证明您不仅是“功能实现者”，更是具备“系统优化”和“AI应用创新”能力的稀缺人才。

### 功能模块三：AI 辅助写作 (AI-Powered Writing Assistance)

**功能描述：** 针对论文写作中最耗时的部分，提供智能化的辅助。`ScholarMind` 可以帮助用户润色语言、根据知识库内容生成论文片段、甚至自动化完成初稿。

*   **技术实现路径:**
    1.  **学术语言润色 (Academic Polishing):**
        *   **描述**: 提供一个“润色”功能。用户输入一段较为口语化的草稿，LLM 会将其改写为更符合学术规范、更书面化的语言。
        *   **产出物**: 一个新的API端点 `/writing/polish`。
    2.  **基于知识库的片段写作 (Context-Aware Snippet Generation):**
        *   **描述**: 用户指定一个主题和写作要求（如“帮我写一段关于GNN在交通流量预测中应用的介绍”），系统首先在知识库中进行RAG检索，然后将检索到的上下文组织起来，喂给LLM生成符合要求的段落（如摘要、Introduction的一部分）。
        *   **产出物**: 一个新的API端点 `/writing/generate_snippet`。
    3.  **【亮点功能】<font color='red'>智能引用推荐 (Smart Citation Suggestion)</font>:**
        *   **功能描述**: 这是一个强大的“**边写边引 (Cite-as-you-write)**”功能。用户在撰写论文时，可以输入一段自己写好的、但尚未添加引用的段落。`ScholarMind` 会智能分析这段话的核心论点，自动在本地知识库中检索支撑这些论点的文献，并将标准的引用标记（如 `[1]`, `(Author, Year)`）插入到文本的适当位置，同时在文末生成对应的参考文献列表。
        *   **技术实现路径**:
            1.  **论点切分**: 使用 NLP 技术或 LLM 将用户输入的段落切分成多个独立的语义论点或句子。
            2.  **批量检索**: 对每一个论点，调用我们已经构建好的高级 RAG 检索管道，在知识库中找到最相关的 Top-K 篇文献或段落。
            3.  **引用决策**: 让 LLM 判断检索到的文献是否确实能支撑原始论点。如果能，则确定引用该文献。
            4.  **文本注入与格式化**: 在原始文本的论点句末尾插入引用标记，并调用独立的格式化工具生成参考文献列表。
        *   **产出物**: 一个新的 API 端点 `/writing/suggest_citations`，接收文本块，返回带引用的文本块和参考文献列表。

### <font color='red'>功能模块四：自动化 Related Work 撰写 (Agent-Powered Related Work Generation)</font>

**功能描述：** 这是 `ScholarMind` 的“杀手级”功能，是 **Agent 技术**的最佳应用场景。用户只需给出一个主题，Agent 就能**自主地在知识库中进行检索、阅读、提炼、总结**，并最终生成一份结构清晰、逻辑连贯的“Related Work”章节初稿，并自动整理好参考文献列表。

*   **技术实现路径:**
    1.  **<font color='red'>Agent化与工具调用 (Agentic Workflow with Tool Calling)</font>:**
        *   **描述**: 引入**工具调用 (Tool Calling)** 思想，让LLM能自主规划并调用您提供的工具集来完成复杂任务。
        *   **定义的工具集**:
            *   `search_papers(query: str, author: str, year_range: tuple)`: 在知识库中检索论文。
            *   `read_and_summarize(paper_ids: list[str], topic: str)`: 阅读并总结指定论文中与特定主题相关的内容。
            *   `synthesize_related_work(summaries: list[str])`: 将多篇论文的摘要综合起来，撰写成一段连贯的综述。
            *   `format_bibliography(paper_ids: list[str], style: str = 'apa')`: 按照指定风格（如 APA, MLA）格式化参考文献列表。
        *   **产出物**: 一个具备自主规划能力的 Related Work 撰写 Agent 服务，通过 API 端点 `/agent/generate_related_work` 提供。

### <font color='red'>【亮点功能】功能模块五：知识库可视化分析 (Knowledge Base Visualization & Analysis)</font>

**功能描述：** 提供一个“上帝视角”来洞察整个知识库。系统可以自动从所有论文中抽取出作者、技术、论文之间的复杂关系，并以**交互式知识图谱**的方式呈现给用户。用户可以直观地看到哪些作者是领域核心，哪些技术是研究热点，以及不同研究方向之间的关联。

*   **技术实现路径:**
    1.  **<font color='red'>基于LLM的知识图谱构建 (LLM-based Knowledge Graph Construction)</font>:**
        *   **描述**: 这是将非结构化文本转化为结构化知识的关键。我们将利用私有化部署的LLM，对知识库中的每一篇论文进行处理，**扮演一个信息抽取（Information Extraction）的角色**。LLM的任务是识别出关键实体（作者、论文、核心技术、数据集等）以及它们之间的关系（如：引用、使用、隶属），并输出为结构化的图数据（节点和边）。
        *   **产出物**: 一个 `knowledge_graph_builder.py` 脚本，负责调用LLM生成并存储知识图谱数据。
    2.  **前端可视化渲染 (Frontend Visualization Rendering):**
        *   **描述**: 在前端，使用 `ECharts`, `D3.js` 或 `Vis.js` 等专业的图表库，加载后端API传来的图数据，并将其渲染成一个用户可以拖拽、缩放、点击的交互式知识图谱。
        *   **产出物**: 一个新的前端页面和组件，用于展示知识图谱。

### 支撑模块：系统优化与评估 (Supporting Modules: Optimization & Evaluation)

**描述：** 为了确保上述所有功能的专业性和可靠性，我们需要建立一套科学的评估和优化体系，并探索最前沿的模型优化技术。

*   **技术实现路径:**
    1.  **构建量化评估体系 (RAG Evaluation):**
        *   **描述**: 集成 `RAGAs` 或 `TruLens` 评估框架，构建一个小的评测数据集，用以量化计算系统的**忠实度 (Faithfulness)、答案相关性 (Answer Relevancy)、上下文精确率/召回率 (Context Precision/Recall)**等核心指标。
        *   **产出物**: 一个 `evaluation.py` 脚本；一份 `evaluation_report.md`，用数据驱动每一次优化。
    2.  **<font color='red'>【终极目标：RL微调】Agent 规划策略优化 (Agent Planning Policy Optimization via RL)</font>:**
        *   **动机**: Agent 完成复杂任务（如撰写Related Work）依赖于一系列工具调用的“决策链”。一个优秀的 Agent 不仅要“会用”工具，更要学会“**聪明地、高效地**”使用工具。通过强化学习，我们可以**优化 Agent 的规划与推理策略本身**。
        *   **RL建模**:
            *   **状态 (State)**: 当前的任务目标和已经收集到的信息。
            *   **动作 (Action)**: Agent 在当前状态下，选择调用哪个**工具**以及传入什么**参数**。
            *   **奖励 (Reward)**: 这是一个**稀疏奖励**场景。只有当 Agent 完成所有步骤生成最终报告后，才能由一个更高阶的模型（如GPT-4o）或用户来给最终产出一个综合质量评分，作为对整个决策链的**总奖励**。
        *   **产出物**: 一个经过 PPO/REINFORCE 算法微调、具备更优规划能力的 LLM Agent；一份阐述如何优化 LLM Agent 推理过程的顶级技术报告，**完美契合 RL+LLM Agent 这一前沿求职方向**。
    3.  **全链路可观测性 (Observability) - (推荐):**
        *   **描述**: 集成 `LangSmith` 或自建日志系统，追踪一次复杂任务（尤其是Agent调用）的全链路，方便调试和定位问题。
        *   **产出物**: 可观测性中间件；`tracing.md` 使用说明。
    4.  **<font color='red'>量化成功指标 (Quantifiable Success Metrics)</font>:**
        *   **描述**: 这里统一存放我们所有核心技术模块的量化目标，将由“构建量化评估体系”模块负责具体评测和生成报告。这些指标是衡量我们项目成功与否的关键，也是写入简历的核心成果。
        *   **具体指标**:
            *   **高级检索策略**: 相较于基线检索，将核心指标 **Context Precision 提升20%**。
            *   **自适应Reranker (RL)**: 将用户对引用来源的**点击率提升30%**。
            *   **智能引用推荐**: 在测试集上达到 **90% 的引用推荐准确率**。
            *   **Agent自动化写作**: 生成的初稿达到**只需少量（~20%）人工修改即可用**的水平。
            *   **知识图谱构建**: 在标注测试集上，实体关系抽取的 **F1 分数达到 85% 以上**。
            *   **Agent策略优化 (RL)**: 将 Agent 生成报告的**平均质量分从 7/10 提升至 9/10**。
            *   **基础RAG评估**: 将系统的 **Faithfulness 从 0.8 提升至 0.95**。
